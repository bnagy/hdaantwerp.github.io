{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring datasets: Exercise chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to the `chat` dataset from Week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a proper exploration of your data (both in 'numbers' and visually, by means of a plot) should always precede any statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load  `datasets/chat/chat.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = pd.read_csv(\"../../datasets/chat/chat.tsv\", sep=\"\\t\")\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new categorical variable: was the participant's submission to the research project large (>500 tokens of chat data) or small (<=500 tokens)?\n",
    "\n",
    "Here we introduce a pandas method called `apply()`. You can use this on `Series` (as here) or whole `DataFrame`s to apply a function to every item (or every row or column in a `DataFrame`) and return the results as a `Series`. You can think of it as a vectorized function. Most of the time, if you feel like you want to loop over a pandas object, what you really want is probably `apply()` -- it is much more efficient and almost always gives you cleaner code.\n",
    "\n",
    "Since our function is so simple, you can use a throwaway Python `lambda` instead of defining a whole function with `def`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat[\"submission\"] = chat.nr_tokens.apply(lambda x: \"large\" if x > 500 else \"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how it would look with a 'real' function:\n",
    "\n",
    "\n",
    "def large_small(n: int) -> str:\n",
    "    if n > 500:\n",
    "        return \"large\"\n",
    "    else:\n",
    "        return \"small\"\n",
    "\n",
    "\n",
    "chat.nr_tokens.apply(large_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we observe a gender difference in submission size (\"small\"/\"large\")? Find the documentation online and create a table with submission sizes per gender using `pd.crosstab()`. Add row and column 'marginal sums'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(chat.submission, chat.gender, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now *normalize* the sums by gender (depending on how you oriented the table this could be rows or columns) to get percentages, and round to three decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(chat.submission, chat.gender, margins=True, normalize=\"columns\").round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Question: \n",
    "> How to interpret these percentages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Exercise:\n",
    "> Now repeat these steps, but normalize by submission size. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two mosaic plots from the original submissiontable (raw frequencies), one by submission (along the x-axis) and one by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "mosaic(chat, [\"submission\", \"gender\"])\n",
    "plt.show()\n",
    "mosaic(chat, [\"gender\", \"submission\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Question:\n",
    "> How to interpret the plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and visualization (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now check whether we can observe a gender difference in emoji use. Start with some basic plots.\n",
    "- Make a scatterplot of `emoticons` vs `nr_tokens`, colored by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(chat, x=\"emoticons\", y=\"nr_tokens\", hue=\"gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the submission size (number of donated tokens: see variable `nr_tokens`) differs among the participants, first create a new variable called \"emoticons_relative\" by dividing the number of emoticons used by the number of tokens. You can inspect this new numeric variable with `summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat[\"emot_rel\"] = chat[\"emoticons\"] / chat[\"nr_tokens\"]\n",
    "chat.emot_rel.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize in a `boxplot` and a `kdeplot` colored by gender.\n",
    "\n",
    "\n",
    "> ##### Question:\n",
    "> What is striking from this boxplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(chat, y=\"emot_rel\", hue=\"gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(chat, x=\"emot_rel\", hue=\"gender\", cut=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple cutoff, delete datapoints with a ratio of >1 for emoji/nr_tokens. Subset the data using `[ ]` and insert your condition as above. Can you check how many datapoints you 'lost'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_cut = chat[chat.emot_rel <= 1]\n",
    "chat.shape[0] - chat_cut.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the boxplot again. It should show fewer outliers (extreme datapoints) now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(chat_cut, y=\"emot_rel\", hue=\"gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that there are still some pretty bad outliers. Last time we used $z$-scaling. This time we will use another common cutoff to delete outliers (i.e. a widely applied rule of thumb),  and delete items that are 1.5 times or more the interquartile range (IQR) above the third quartile, and 1.5 times or more the IQR below the first quartile. To get the IQR, either use `quantile()`or `describe()`.\n",
    "\n",
    "Check how many datapoints we lost this time: you'll see that this cutoff is a lot more drastic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1, q3 = chat.emot_rel.quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "print(f\"IQR: {iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_extracut = chat[\n",
    "    (chat.emot_rel >= (q1 - 1.5 * iqr)) & (chat.emot_rel <= (q3 + 1.5 * iqr))\n",
    "]\n",
    "chat.shape[0] - chat_extracut.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(chat_extracut, y=\"emot_rel\", hue=\"gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(chat_extracut, x=\"emot_rel\", hue=\"gender\", cut=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with chat_repeated: repeated measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have read on the slides on the different datasets, chat_repeated is a larger version of chat. An important difference is that chat_repeated (hence its name...) contains **repeated measurements**, i.e. multiple observations for one and the same subject. This issue of **dependent data** (including repeated measurements) versus **independent data** (no repeated measurements) will become very important later in the course, since data independence is a major assumption for many statistical tests and models (and alternative methods need to be applied to dependent data). Right now, we just show how to verify whether or not your dataset contains such repeated measurements.\n",
    "\n",
    "> ##### EXERCISE\n",
    "> Let's start with chat. Are there multiple observations (datapoints) for 1 subject? There are multiple ways to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for chat_repeated. Load the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Version History\n",
    "\n",
    "Current: v1.0.1\n",
    "\n",
    "27/9/24: 1.0.0: first draft, BN\n",
    "08/10/24: 1.0.1: proofread + typos, MK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
