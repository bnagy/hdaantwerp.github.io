{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations: $r$, $\\tau$, $\\rho$\n",
    "\n",
    "## Pearson's $r$\n",
    "*Gries, chapter 3, pp. 147-156*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"mathtext.default\": \"regular\"})\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://dm.cs.tu-dortmund.de/en/mlbits/foundations-correlation-causation/tylervigen-correlation-cheese-bedsheets.svg>\n",
    "<small>Tyler Vigen, http://www.tylervigen.com/spurious-correlations, CC BY 4.0</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the dataset with the metadata on the Arthurian manuscripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../datasets/arthur/manuscripts.csv\", index_col=0)\n",
    "df.columns = df.columns.str.replace(\"-\", \"_\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sprint on plotting, we've worked quite a lot already with the physical properties, i.e. the size of a manuscript's pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = df[[\"leaf_height\", \"leaf_width\", \"text_height\", \"text_width\"]].dropna()\n",
    "# New tricks!\n",
    "g = sns.JointGrid(dimensions, y=\"leaf_height\", x=\"leaf_width\")\n",
    "g.plot_joint(sns.scatterplot)\n",
    "g.plot_marginals(sns.kdeplot, fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly (and expectedly), we see that there is a special relationship between the height and width of a page in this data. The scatter of the points in this graph is such that we can say: *the wider a page is, the taller it will be* (and the other way round). Such a special relationship between two numeric (ratio-scaled) variables is called a **correlation**. **Bivariate statistics** offer us useful instruments to quantify how strong such correlations are by computing a test statistic or **correlation coefficient** that is typically known as $r$ (although there exist a number of common alternatives).\n",
    "\n",
    "For the most common tests, $r$ will lie in the range between -1 and 1. A positive $r$ implies a positive relationship between two variables (\"the more ..., the more ...\" or \"the higher ..., the higher ...\"); a negative correlation means that the two variables demonstrate a similar pattern in co-behaviour, but this time in the opposite direction: \"the more this, the less that\" etc., but also: \"the fewer ... the more\" or \"the lower... the higher...\". Such relationships tie in with what is known as **directly proportional** and **inversely proportional** relationships between variables.\n",
    "\n",
    "An $r$ of 0 implies that there is no correlation at all. It is therefore useful to make a distinction between the **strength** and **direction** of a correlation: the **direction** relates to the **sign** of $r$ (i.e. a positive or a negative correlation). The strength relates to the actual (absolute) scalar value of $r$: the closer it is to either +1 or -1, the **stronger** the correlation is (be it negative, or positive). Table 18 in Gries (p. 147) offers a useful overview of the terms that  can be used to characterize such a correlation. With $0.7 > r > 1.0$, you can for instance speak of a \"very high, positive correlation\".\n",
    "\n",
    "<img src=\"./correlations.png\" />\n",
    "\n",
    "The most common statistic to calculate the **correlation coefficient** $r$ is the (famous) **Pearson product-moment correlation**. Gries details the calculation at greater length, and shows how it depends on the calculation of another common measure, the **covariance**. To compute the Pearson coefficient we can use the method `sp.stats.pearsonr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.pearsonr(dimensions.leaf_height, dimensions.leaf_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a very high, positive correlation coefficient (the statistic reported is Pearson's $r$), as we could have guessed from the plot. We also get back a (very low) $p$-value, assuring us that the correlation is \"definitely not zero\" (which is the **null hypothesis** associated with this procedure). This is a two-tailed version of the test. If we'd like to test more specific for a positive correlation, we could have gone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.pearsonr(dimensions.leaf_height, dimensions.leaf_width, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the formulation of the alternative hypothesis changed in the summary of the method's result. Other than that, there isn't a large difference. As always, a non-directional hypothesis is a bit \"lame\", in comparison to a bolder, directional version. The **point estimate** for $r$ that is reported is .85, we can also get a so-called **confidence interval** on that estimate. Explaining how this is calculated exactly would take us too far, but this gives you an idea of the range of values (below or above the parameter estimate) that the estimation procedure would still find credible for this parameter. In this case, for instance, this range suggests that the true $r$ is more likely to be higher than lower than the point estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.stats.pearsonr(\n",
    "    dimensions.leaf_height, dimensions.leaf_width, alternative=\"greater\"\n",
    ")\n",
    "res.confidence_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kendall's $\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pearson procedure, however, comes with a major drawback -- and by this time you can probably already guess what that is: *it requires both of your variables to be normally distributed*. (This restriction is controversial: some people claim that the condition of normality doesn't have to be fulfilled necessarily.) Let's check whether that was in fact the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Height normality p-value: {sp.stats.shapiro(dimensions.leaf_height).pvalue.round(6)}\\n\"\n",
    "    + f\"Width normality p-value: {sp.stats.shapiro(dimensions.leaf_width).pvalue.round(6)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(dimensions.leaf_height, line=\"s\")\n",
    "plt.show()\n",
    "sm.qqplot(dimensions.leaf_width, line=\"s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch... Neither of our two dimension columns are normally distributed, so **we weren't allowed to run the test in the first place**! (This is in fact surprising, in the sense that one could well hypothesize that medieval manuscripts had an average \"length\", with some fairly predictable, symmetric spread around the mean.) Theoretically, that means we should look for another test, which is a tad frustrating, because were perfectly able to run the test technically and we even got a sensible output!\n",
    "\n",
    "As before: *ranks to the rescue!* Pearson has a non-parametric counterpart that is used a lot, called **Kendall's $\\tau$** (*tau*), which is used a lot across science. This method too resorts to the ranks of values instead of the actual values, explaining why this method bypasses the normality restriction and is much less sensitive to outliers. You can run using `sp.stats.kendalltau`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.stats.kendalltau(dimensions.leaf_height, dimensions.leaf_width)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a comparably large $\\tau$ statistic, in the same ballpark as before, but theoretically much sounder (remember how non-parametric tests will typically be a bit more conservative). Roughly speaking, the method will replace the values by the ranks that the values have in each sample. Next, it will compare how the ranks co-vary (instead of the actual values), so that we don't have to care about the distribution any longer, which is really convenient.\n",
    "\n",
    "Note that both the Pearson and the Kendall procedure don't care about the order in which you feed the two samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp.stats.kendalltau(dimensions.leaf_height, dimensions.leaf_width))\n",
    "print(sp.stats.kendalltau(dimensions.leaf_width, dimensions.leaf_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficients are useful to be more precise when discussing the relationship between two variables. Take for instance, the relationship between the width and height of the writing surface on each page, instead of the entire page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = sns.JointGrid(dimensions, y=\"leaf_height\", x=\"leaf_width\")\n",
    "g1.plot_joint(sns.regplot, color=\"slateblue\", ci=None, truncate=False)\n",
    "g1.plot_marginals(sns.kdeplot, color=\"slateblue\", fill=True)\n",
    "plt.show()\n",
    "g2 = sns.JointGrid(dimensions, y=\"text_height\", x=\"text_width\")\n",
    "g2.plot_joint(sns.regplot, color=\"mediumorchid\", ci=None, truncate=False)\n",
    "g2.plot_marginals(sns.kdeplot, color=\"mediumorchid\", fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there's also a positive correlation between those two dimensions, but when you compare the two plots and draw and imaginary line through both sample clouds, the correlation seems \"less good\", in the sense that there's more \"scatter\" around the imaginary line. Using Kendall's `tau` we can be more precise as to this \"less good\" correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp.stats.kendalltau(dimensions.leaf_height, dimensions.leaf_width))\n",
    "print(sp.stats.kendalltau(dimensions.text_height, dimensions.text_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the $p$-value shows that we shouldn't doubt that there's a significant correlation in each case, but the actual $\\tau$ is quite a bit larger in the case of leaf dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very common application of Kendall's $\\tau$ are **time series**: often you'll want to know whether some variable has become larger or smaller over time and how consistent the increase/decrease has been. For answering such questions, Kendall is simply great. At first sight, this might seem as a univariate problem (because you have only one variable, no?), but in reality,  you'll be comparing the values of that variable to a time variable, which automatically becomes your second (\"scalar\") variable. Just to give you a quick example, we return our Harry Potter sentence length data. A clear trend in this data that seems obvious when we plot it, is that sentences have become longer throughout the series (in either variety of English):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potter = pd.read_csv(\"../../datasets/potter/lengths.csv\")\n",
    "potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potter.plot.scatter(x=\"index\", y=\"UK\", color=\"slateblue\")\n",
    "plt.show()\n",
    "potter.plot.scatter(x=\"index\", y=\"US\", color=\"mediumorchid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of multiple factors here: Hatsune Mikue's books have gotten more complex, involving \"darker\" themes over time and perhaps this process of thematic maturization has also effected the writing style and complexity of the language. Also, perhaps her editors have become less obtrusive over the years and left the author more freedom in making these kinds of long sentences (that they would split up with starting authors).\n",
    "\n",
    "How can we formulate conclusive statements about this development? Using Kendall's $\\tau$ we can now issue a more principled statement about whether or not there has been a steady increase in Hatsune Miku's sentence length over time. Note that we use a directional hypothesis here, because that's what our exploration of the data suggested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"UK sentences: {sp.stats.kendalltau(potter.UK, potter.index, alternative='greater')}\"\n",
    ")\n",
    "print(\n",
    "    f\"US sentences: {sp.stats.kendalltau(potter.US, potter.index, alternative='greater')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is \"yes\": there is a statistically significant growth of Miku's sentences in length over time, because the $p$-value is sufficiently small to reject the null hypothesis that $\\tau$ would be zero or smaller. Did you see the little trick that we applied, by the way? To obtain a second variable we just took the index of the chapter to calculate the correlation against. This is very common in **time series analyses**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman's $\\rho$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly used measure is **Spearman's $\\rho$**. This function is not mentioned by Gries, but it is used quite often in computational studies, and it also has the major advantage that it doesn't require your data to be normally distributed. Like $\\tau$ it operates on ranks -- which is always a safer bet. Like other rank measures it trades (a little bit of) precision for a (much) broader applicability. It's available from `sp.stats.spearmanr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp.stats.spearmanr(dimensions.leaf_height, dimensions.leaf_width))\n",
    "print(sp.stats.kendalltau(dimensions.leaf_height, dimensions.leaf_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a different test statistic, but largely the same result (and theoretically sound). Finally, note that all of the correlation testing procedures above require **paired data** (with equal sizes across all samples involved): for instance in the time series example, each actual measurement must be paired with exactly one time indication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final warning is that association measures can be unreliable for small samples (less than about 500). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## EXTRA HARD: Bootstrapping $p$-values\n",
    "\n",
    "> When we have small samples, we can check the results of many tests by using *permutation testing*. The basic idea is not too difficult, but the code is complicated. First, we take many *permutations* of the data. In this case we shuffle the order of the chapters over and over, and calculate the specified statistic many times. Then we **empirically** compare how many of the random permutations have a statistic more extreme than the one we observed. Recall that the original idea of the $p$-value is \"how likely would it be for us to observe this statistic if $H_0$ is true\". So far we have been *calculating* this probability, but here we are using *randomness* to simulate it. \n",
    "\n",
    "> Bootstrap statistics are methodologically very clean, but they can be *slow to calculate* and *difficult to code*. They will often be *more conservative* than theoretical $p$-values (but this is mostly a good thing). You won't be examined on these, but they are good to know about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is adapted directly from the [scipy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.permutation_test.html), with some added comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can transform the rho statistic so that it is theoretically distributed according to a\n",
    "# distribution we know about, in this case Student's T distribution.\n",
    "\n",
    "# First we draw the theoretical curve for the transformed stat.\n",
    "dof = len(potter.UK) - 2  # strange DOF because of the transformation\n",
    "dist = sp.stats.t(df=dof)\n",
    "t_vals = np.linspace(-5, 5, 100)\n",
    "pdf = dist.pdf(t_vals)\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "\n",
    "def plot(ax):  # we'll reuse this\n",
    "    ax.plot(t_vals, pdf)\n",
    "    ax.set_title(\"Spearman's Rho Test Null Distribution\")\n",
    "    ax.set_xlabel(\"statistic\")\n",
    "    ax.set_ylabel(\"probability density\")\n",
    "\n",
    "\n",
    "plot(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(x):\n",
    "    # Explore many possible pairings by permuting `x`\n",
    "    rs = sp.stats.spearmanr(x, potter.index).statistic\n",
    "    # special transformation:\n",
    "    transformed = rs * np.sqrt(dof / ((rs + 1.0) * (1.0 - rs)))\n",
    "    return transformed\n",
    "\n",
    "\n",
    "# reproducible results!\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# It might seem weird that we are only permuting one element of the pairs, but it works out the same\n",
    "# because Spearman's R doesn't care about order.\n",
    "res = sp.stats.permutation_test(\n",
    "    (potter.UK,),\n",
    "    statistic,\n",
    "    alternative=\"greater\",\n",
    "    permutation_type=\"pairings\",\n",
    "    n_resamples=9999,\n",
    "    random_state=rng,\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "plot(ax)\n",
    "ax.hist(res.null_distribution, np.linspace(-10, 10, 50), density=True)\n",
    "ax.legend(\n",
    "    [\n",
    "        \"asymptotic approximation\\n(many observations)\",\n",
    "        f\"exact \\n({len(res.null_distribution)} permutations)\",\n",
    "    ]\n",
    ")\n",
    "trans = ax.get_xaxis_transform()  # lets us specify height by percentage\n",
    "plt.text(\n",
    "    res.statistic - 4.2,\n",
    "    0.8,\n",
    "    f\"T={res.statistic.round(3)}\\n(transformed $\\\\rho$)\",\n",
    "    color=\"red\",\n",
    "    transform=trans,\n",
    ")\n",
    "ax.axvline(res.statistic, linestyle=\"--\", color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only this high because we only did 9999 simulations! If we had time to do many more it\n",
    "# would approach the theoretical p-value from the analytic test.\n",
    "\n",
    "res.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://imgs.xkcd.com/comics/correlation.png />\n",
    "\n",
    "<small>XKCD, https://xkcd.com/552/ License CC-BY-NC 2.5</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Version History\n",
    "\n",
    "Current: v1.0.1\n",
    "\n",
    "3/10/24: 1.0.0: first draft, BN\n",
    "09/10/24: 1.0.1: proofread, MK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
