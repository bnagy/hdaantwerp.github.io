{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4: homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\"mathtext.default\": \"regular\", \"figure.dpi\": 300, \"figure.figsize\": (6, 6)}\n",
    ")\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Arthurian manuscripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following preprocessing steps (you get the code for free):\n",
    "- Load the Arthurian manuscripts metadata and restrict it to a subset of the columns\n",
    "- Drop any incomplete rows\n",
    "- Only consider rows for which the script type is \"cursive\" or \"textualis\" (which are the most common script types)\n",
    "- As in 4-2, drop entries with 'obvious' data entry issues\n",
    "- Calculate the 'text_surface' (surface of the writing area) and 'leaf_surface' (surface of the full page) and assign these to new columns in the dataset (result in $cm^2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../datasets/arthur/manuscripts.csv\", index_col=0)\n",
    "df.columns = df.columns.str.replace(\"-\", \"_\")\n",
    "\n",
    "page_cols = [\"leaf_height\", \"leaf_width\", \"text_height\", \"text_width\"]\n",
    "mss = df[\n",
    "    page_cols\n",
    "    + [\n",
    "        \"script\",\n",
    "        \"material\",\n",
    "        \"physical_type\",\n",
    "    ]\n",
    "].dropna()\n",
    "mss = mss[mss.script.isin([\"textualis\", \"cursive\"])]\n",
    "\n",
    "# Divide by 10 for mm -> cm\n",
    "mss[page_cols] = mss[page_cols].apply(lambda x: x / 10)\n",
    "\n",
    "mss[\"text_area\"] = mss.text_height * mss.text_width\n",
    "mss[\"leaf_area\"] = mss.leaf_height * mss.leaf_width\n",
    "\n",
    "bad = (\n",
    "    (mss.leaf_height < mss.text_height)\n",
    "    | (mss.leaf_width < mss.text_width)\n",
    "    | ((mss.leaf_area) < 0.001)\n",
    "    | ((mss.text_area) < 0.001)\n",
    ")\n",
    "mss = mss[~bad]\n",
    "mss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run a univariate linear model in which you use a manuscript's `leaf_area` to predict its `text_area`. Print the model summary.\n",
    "\n",
    "> CHECK What is the *dependent variable*? What is the *predictor*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **FROM THE DATAFRAME** plot `leaf_area` vs `text_area` as a scatterplot with `sns.scatterplot`. Convention says that you should have the **dependent** variable on the y-axis, but either way, make sure the regression line seems to fit!\n",
    "\n",
    "2. **MANUALLY** (not using `regplot` or seaborn tricks) add the regression line from the model parameters using `axline()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the model to retrieve the estimated coefficients for the regression formula ($mx + c$). **Manually** (i.e. without a function call) calculate which `text_area` the model would propose for a manuscript with a `leaf_area` of 500 $cm^2$, 700 $cm^2$ and 1500 $cm^2$ respectively, by copying the coefficients into the formula for the regression line. Validate your result, by calling `predict()` on the model for all three cases simultaneously.\n",
    "\n",
    "> TIP: This is a little fiddly. The easiest way for one variable is to pass a `dict` where the key is the predictor and the value is a `list` of values for which we want predictions. For multivariate models it will be easiest to pass a whole `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supplement the linear model which you just ran with the calculation of one of three correlation tests that we saw (\"spearman\", \"kendall\" or \"pearson\"). Justify your choice. Describe the correlation by looking up (*Gries, p. 147*) the suitable wording for the correlation coefficient which you obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, consider the following three categorical predictors (1) `physical_type`, (2) `script`, and (3) `material`. Run a separate `ols()` regression for each of these features as predictors for a manuscript's `leaf_area`. Provide an interpretation for each of the coefficients you obtain. Produce boxplots for each experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For obvious reasons, `leaf_area` is a good predictor for \"text_area\" (since they correlate), whereas `physical_type` also seems useful. Combine both `leaf_area` and `physical_type` as predictors into a single model that predicts `text_area`. Inspect whether and how the dependent variables complement each other. Compare the two single-variate models to the bivariate model. Which model would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Harry Potter and the New Chapter\n",
    "\n",
    "Reload the data on sentence lengths in the Harry Potter novels. Consider the UK sentence lengths and:\n",
    "1. Produce a scatterplot in which you plot the sentence lengths in the UK chapters as a function of their (ascending) chapter index in this oeuvre.\n",
    "- Provide a suitable title and descriptive labels for the horizontal and vertical axis.\n",
    "2. Run a linear model and plot the regression line (in red) on top of the scatterplot. Report on the result of the linear model on the basis of the model's summary. Answer the question:\n",
    "  - What is the average increase/decrease in tokens for every consecutive chapter in this series, according to this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if a new chapter were produced at the end of the final book, use the statsmodels `get_prediction` API to predict its *mean length* with an associated 95% confidence interval.\n",
    "\n",
    "HINT: If you get stuck, you might have forgotten the `summary_frame()` method..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://imgs.xkcd.com/comics/linear_regression.png>\n",
    "\n",
    "<small>[XKCD](https://xkcd.com/1725/) CC-BY-NC 2.5</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Version History\n",
    "\n",
    "Current: v1.0.1\n",
    "\n",
    "8/10/24: 1.0.0: first draft, BN\n",
    "09/10/24: 1.0.1: proofread, MK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
